{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865572ab",
   "metadata": {},
   "source": [
    "### Guardrails\n",
    "\n",
    "Implement safety checks and content filtering for your agents.\n",
    "Guardrails help you build safe, compliant AI applications by validating and filtering content at key points in your agent’s execution. They can detect sensitive information, enforce content policies, validate outputs, and prevent unsafe behaviors before they cause problems.\n",
    "\n",
    "Common use cases include:\n",
    "1. Preventing PII leakage\n",
    "2. Detecting and blocking prompt injection attacks\n",
    "3. Blocking inappropriate or harmful content\n",
    "4. Enforcing business rules and compliance requirements\n",
    "5. Validating output quality and accuracy\n",
    "\n",
    "You can implement guardrails using middleware to intercept execution at strategic points - before the agent starts, after it completes, or around model and tool calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6f63e",
   "metadata": {},
   "source": [
    "### Built-in Guardrails\n",
    "\n",
    "#### PII DETECTION\n",
    "LangChain provides built-in middleware for detecting and handling Personally Identifiable Information (PII) in conversations. This middleware can detect common PII types like emails, credit cards, IP addresses, and more.\n",
    "\n",
    "The PII middleware supports multiple strategies for handling detected PII:\n",
    "1. redact -> Replace with [REDACTED_{PII_TYPE}]\t          -> [REDACTED_EMAIL]\n",
    "2. mask\t  -> Partially obscure (e.g., last 4 digits)\t  -> ****-****-****-1234\n",
    "3. hash\t  -> Replace with deterministic hash\t          -> a8f5f167...\n",
    "4. block  -> Raise exception when detected\t              -> Error thrown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[customer_service_tool, email_tool],\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"redact\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "        # Mask credit cards in user input\n",
    "        PIIMiddleware(\n",
    "            \"credit_card\",\n",
    "            strategy=\"mask\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "        # Block API keys - raise error if detected\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# When user provides PII, it will be handled according to the strategy\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"My email is john.doe@example.com and card is 5105-1051-0510-5100\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd29a21",
   "metadata": {},
   "source": [
    "### Human-in-the-loop\n",
    "\n",
    "LangChain provides built-in middleware for requiring human approval before executing sensitive operations. This is one of the most effective guardrails for high-stakes decisions.\n",
    "Human-in-the-loop middleware is helpful for cases such as financial transactions and transfers, deleting or modifying production data, sending communications to external parties, and any operation with significant business impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333cc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, send_email_tool, delete_database_tool],\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                # Require approval for sensitive operations\n",
    "                \"send_email\": True,\n",
    "                \"delete_database\": True,\n",
    "                # Auto-approve safe operations\n",
    "                \"search\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    # Persist the state across interrupts\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Human-in-the-loop requires a thread ID for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"some_id\"}}\n",
    "\n",
    "# Agent will pause and wait for approval before executing sensitive tools\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to the team\"}]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "    config=config  # Same thread ID to resume the paused conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0c606",
   "metadata": {},
   "source": [
    "### Custom GuardRails\n",
    "#### Before agent guardrails\n",
    "Use “before agent” hooks to validate requests once at the start of each invocation. This is useful for session-level checks like authentication, rate limiting, or blocking inappropriate requests before any processing begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "class ContentFilterMiddleware(AgentMiddleware):\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "\n",
    "    def __init__(self, banned_keywords: list[str]):\n",
    "        super().__init__()\n",
    "        self.banned_keywords = [kw.lower() for kw in banned_keywords]\n",
    "\n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # Get the first user message\n",
    "        if not state[\"messages\"]:\n",
    "            return None\n",
    "\n",
    "        first_message = state[\"messages\"][0]\n",
    "        if first_message.type != \"human\":\n",
    "            return None\n",
    "\n",
    "        content = first_message.content.lower()\n",
    "\n",
    "        # Check for banned keywords\n",
    "        for keyword in self.banned_keywords:\n",
    "            if keyword in content:\n",
    "                # Block execution before any processing\n",
    "                return {\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "                    }],\n",
    "                    \"jump_to\": \"end\"\n",
    "                }\n",
    "\n",
    "        return None\n",
    "\n",
    "# Use the custom guardrail\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, calculator_tool],\n",
    "    middleware=[\n",
    "        ContentFilterMiddleware(\n",
    "            banned_keywords=[\"hack\", \"exploit\", \"malware\"]\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6deaa",
   "metadata": {},
   "source": [
    "#### After agent guardrails\n",
    "Use “after agent” hooks to validate final outputs once before returning to the user. This is useful for model-based safety checks, quality validation, or final compliance scans on the complete agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce37c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.messages import AIMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Any\n",
    "\n",
    "class SafetyGuardrailMiddleware(AgentMiddleware):\n",
    "    \"\"\"Model-based guardrail: Use an LLM to evaluate response safety.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.safety_model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def after_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # Get the final AI response\n",
    "        if not state[\"messages\"]:\n",
    "            return None\n",
    "\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if not isinstance(last_message, AIMessage):\n",
    "            return None\n",
    "\n",
    "        # Use a model to evaluate safety\n",
    "        safety_prompt = f\"\"\"Evaluate if this response is safe and appropriate.\n",
    "        Respond with only 'SAFE' or 'UNSAFE'.\n",
    "\n",
    "        Response: {last_message.content}\"\"\"\n",
    "\n",
    "        result = self.safety_model.invoke([{\"role\": \"user\", \"content\": safety_prompt}])\n",
    "\n",
    "        if \"UNSAFE\" in result.content:\n",
    "            last_message.content = \"I cannot provide that response. Please rephrase your request.\"\n",
    "\n",
    "        return None\n",
    "\n",
    "# Use the safety guardrail\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, calculator_tool],\n",
    "    middleware=[SafetyGuardrailMiddleware()],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I make explosives?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6722b8d",
   "metadata": {},
   "source": [
    "#### Combine multiple guardrails\n",
    "You can stack multiple guardrails by adding them to the middleware array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c79f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware, HumanInTheLoopMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, send_email_tool],\n",
    "    middleware=[\n",
    "        # Layer 1: Deterministic input filter (before agent)\n",
    "        ContentFilterMiddleware(banned_keywords=[\"hack\", \"exploit\"]),\n",
    "\n",
    "        # Layer 2: PII protection (before and after model)\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_output=True),\n",
    "\n",
    "        # Layer 3: Human approval for sensitive tools\n",
    "        HumanInTheLoopMiddleware(interrupt_on={\"send_email\": True}),\n",
    "\n",
    "        # Layer 4: Model-based safety check (after agent)\n",
    "        SafetyGuardrailMiddleware(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4e513",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "Large Language Models (LLMs) are powerful, but they have two key limitations:\n",
    "1. Finite context — they can’t ingest entire corpora at once.\n",
    "2. Static knowledge — their training data is frozen at a point in time.\n",
    "Retrieval addresses these problems by fetching relevant external knowledge at query time. This is the foundation of Retrieval-Augmented Generation (RAG): enhancing an LLM’s answers with context-specific information.\n",
    "\n",
    "Retrieval allows LLMs to access relevant context at runtime. But most real-world applications go one step further: they integrate retrieval with generation to produce grounded, context-aware answers.\n",
    "This is the core idea behind Retrieval-Augmented Generation (RAG). The retrieval pipeline becomes a foundation for a broader system that combines search with generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eed4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    rewritten_query: str\n",
    "    documents: list[str]\n",
    "    answer: str\n",
    "\n",
    "# WNBA knowledge base with rosters, game results, and player stats\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_texts([\n",
    "    # Rosters\n",
    "    \"New York Liberty 2024 roster: Breanna Stewart, Sabrina Ionescu, Jonquel Jones, Courtney Vandersloot.\",\n",
    "    \"Las Vegas Aces 2024 roster: A'ja Wilson, Kelsey Plum, Jackie Young, Chelsea Gray.\",\n",
    "    \"Indiana Fever 2024 roster: Caitlin Clark, Aliyah Boston, Kelsey Mitchell, NaLyssa Smith.\",\n",
    "    # Game results\n",
    "    \"2024 WNBA Finals: New York Liberty defeated Minnesota Lynx 3-2 to win the championship.\",\n",
    "    \"June 15, 2024: Indiana Fever 85, Chicago Sky 79. Caitlin Clark had 23 points and 8 assists.\",\n",
    "    \"August 20, 2024: Las Vegas Aces 92, Phoenix Mercury 84. A'ja Wilson scored 35 points.\",\n",
    "    # Player stats\n",
    "    \"A'ja Wilson 2024 season stats: 26.9 PPG, 11.9 RPG, 2.6 BPG. Won MVP award.\",\n",
    "    \"Caitlin Clark 2024 rookie stats: 19.2 PPG, 8.4 APG, 5.7 RPG. Won Rookie of the Year.\",\n",
    "    \"Breanna Stewart 2024 stats: 20.4 PPG, 8.5 RPG, 3.5 APG.\",\n",
    "])\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "@tool\n",
    "def get_latest_news(query: str) -> str:\n",
    "    \"\"\"Get the latest WNBA news and updates.\"\"\"\n",
    "    # Your news API here\n",
    "    return \"Latest: The WNBA announced expanded playoff format for 2025...\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    tools=[get_latest_news],\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "class RewrittenQuery(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def rewrite_query(state: State) -> dict:\n",
    "    \"\"\"Rewrite the user query for better retrieval.\"\"\"\n",
    "    system_prompt = \"\"\"Rewrite this query to retrieve relevant WNBA information.\n",
    "The knowledge base contains: team rosters, game results with scores, and player statistics (PPG, RPG, APG).\n",
    "Focus on specific player names, team names, or stat categories mentioned.\"\"\"\n",
    "    response = model.with_structured_output(RewrittenQuery).invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": state[\"question\"]}\n",
    "    ])\n",
    "    return {\"rewritten_query\": response.query}\n",
    "\n",
    "def retrieve(state: State) -> dict:\n",
    "    \"\"\"Retrieve documents based on the rewritten query.\"\"\"\n",
    "    docs = retriever.invoke(state[\"rewritten_query\"])\n",
    "    return {\"documents\": [doc.page_content for doc in docs]}\n",
    "\n",
    "def call_agent(state: State) -> dict:\n",
    "    \"\"\"Generate answer using retrieved context.\"\"\"\n",
    "    context = \"\\n\\n\".join(state[\"documents\"])\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {state['question']}\"\n",
    "    response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
    "    return {\"answer\": response[\"messages\"][-1].content_blocks}\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(State)\n",
    "    .add_node(\"rewrite\", rewrite_query)\n",
    "    .add_node(\"retrieve\", retrieve)\n",
    "    .add_node(\"agent\", call_agent)\n",
    "    .add_edge(START, \"rewrite\")\n",
    "    .add_edge(\"rewrite\", \"retrieve\")\n",
    "    .add_edge(\"retrieve\", \"agent\")\n",
    "    .add_edge(\"agent\", END)\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "result = workflow.invoke({\"question\": \"Who won the 2024 WNBA Championship?\"})\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
