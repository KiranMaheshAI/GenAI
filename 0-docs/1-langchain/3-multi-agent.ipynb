{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65d72cd",
   "metadata": {},
   "source": [
    "# Multi Agents\n",
    "\n",
    "Multi-agent systems coordinate specialized components to tackle complex workflows.Multi-agent patterns are particularly valuable when a single agent has too many tools and makes poor decisions about which to use, when tasks require specialized knowledge with extensive context (long prompts and domain-specific tools), or when you need to enforce sequential constraints that unlock capabilities only after certain conditions are met\n",
    "\n",
    "When developers say they need “multi-agent,” they’re usually looking for one or more of these capabilities:\n",
    "1. Context management: Provide specialized knowledge without overwhelming the model’s context window. If context were infinite and latency zero, you could dump all knowledge into a single prompt — but since it’s not, you need patterns to selectively surface relevant information.\n",
    "2. Distributed development: Allow different teams to develop and maintain capabilities independently, composing them into a larger system with clear boundaries.\n",
    "3. Parallelization: Spawn specialized workers for subtasks and execute them concurrently for faster results.\n",
    "\n",
    "Ref: https://docs.langchain.com/oss/python/langchain/multi-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082838d",
   "metadata": {},
   "source": [
    "## Patterns\n",
    "\n",
    "Here are the main patterns for building multi-agent systems, each suited to different use cases:\n",
    "1. Subagents: A main agent coordinates subagents as tools. All routing passes through the main agent, which decides when and how to invoke each subagent.\n",
    "2. Handoffs: Behavior changes dynamically based on state. Tool calls update a state variable that triggers routing or configuration changes, switching agents or adjusting the current agent’s tools and prompt.\n",
    "3. Skills: Specialized prompts and knowledge loaded on-demand. A single agent stays in control while loading context from skills as needed.\n",
    "4. Router: A routing step classifies input and directs it to one or more specialized agents. Results are synthesized into a combined response.\n",
    "5. Custom Workflow: Build bespoke execution flows with LangGraph, mixing deterministic logic and agentic behavior. Embed other patterns as nodes in your workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba98ba",
   "metadata": {},
   "source": [
    "## SubAgents\n",
    "\n",
    "In the subagents architecture, a central main agent (often referred to as a supervisor) coordinates subagents by calling them as tools. The main agent decides which subagent to invoke, what input to provide, and how to combine results. Subagents are stateless—they don’t remember past interactions, with all conversation memory maintained by the main agent. This provides context isolation: each subagent invocation works in a clean context window, preventing context bloat in the main conversation.\n",
    "\n",
    "Ref: https://docs.langchain.com/oss/python/langchain/multi-agent/subagents\n",
    "\n",
    "Key characteristics\n",
    "1. Centralized control: All routing passes through the main agent\n",
    "2. No direct user interaction: Subagents return results to the main agent, not the user (though you can use interrupts within a subagent to allow user interaction)\n",
    "3. Subagents via tools: Subagents are invoked via tools\n",
    "4. Parallel execution: The main agent can invoke multiple subagents in a single turn\n",
    "\n",
    "\n",
    "Supervisor vs. Router: A supervisor agent (this pattern) is different from a router. The supervisor is a full agent that maintains conversation context and dynamically decides which subagents to call across multiple turns. A router is typically a single classification step that dispatches to agents without maintaining ongoing conversation state.\n",
    "\n",
    "While subagents typically return results to the main agent rather than conversing directly with users, you can use interrupts within a subagent to pause execution and gather user input. This is useful when a subagent needs clarification or approval before proceeding. The main agent remains the orchestrator, but the subagent can collect information from the user mid-task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ccd2d",
   "metadata": {},
   "source": [
    "### Design Decisions:\n",
    "\n",
    "When implementing the subagents pattern, you’ll make several key design choices.\n",
    "\n",
    "#### Sync vs. async\n",
    "1. Synchronous (default): By default, subagent calls are synchronous—the main agent waits for each subagent to complete before continuing. Use sync when the main agent’s next action depends on the subagent’s result.\n",
    "2. Asynchronous: Use asynchronous execution when the subagent’s work is independent—the main agent doesn’t need the result to continue conversing with the user. The main agent kicks off a background job and remains responsive.\n",
    "\n",
    "#### Tool Patterns\n",
    "There are two main ways to expose subagents as tools:\n",
    "1. Tool per agent: The key idea is wrapping subagents as tools that the main agent can call. The main agent invokes the subagent tool when it decides the task matches the subagent’s description, receives the result, and continues orchestration.\n",
    "2. Single dispatch tool: An alternative approach uses a single parameterized tool to invoke ephemeral sub-agents for independent tasks. Unlike the tool per agent approach where each sub-agent is wrapped as a separate tool, this uses a convention-based approach with a single task tool: the task description is passed as a human message to the sub-agent, and the sub-agent’s final message is returned as the tool result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9100c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Sub-agents developed by different teams\n",
    "research_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    prompt=\"You are a research specialist...\"\n",
    ")\n",
    "\n",
    "writer_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    prompt=\"You are a writing specialist...\"\n",
    ")\n",
    "\n",
    "# Registry of available sub-agents\n",
    "SUBAGENTS = {\n",
    "    \"research\": research_agent,\n",
    "    \"writer\": writer_agent,\n",
    "}\n",
    "\n",
    "@tool\n",
    "def task(\n",
    "    agent_name: str,\n",
    "    description: str\n",
    ") -> str:\n",
    "    \"\"\"Launch an ephemeral subagent for a task.\n",
    "\n",
    "    Available agents:\n",
    "    - research: Research and fact-finding\n",
    "    - writer: Content creation and editing\n",
    "    \"\"\"\n",
    "    agent = SUBAGENTS[agent_name]\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": description}\n",
    "        ]\n",
    "    })\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "# Main coordinator agent\n",
    "main_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[task],\n",
    "    system_prompt=(\n",
    "        \"You coordinate specialized sub-agents. \"\n",
    "        \"Available: research (fact-finding), \"\n",
    "        \"writer (content creation). \"\n",
    "        \"Use the task tool to delegate work.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad630462",
   "metadata": {},
   "source": [
    "#### Subagent outputs\n",
    "Customize what the main agent receives back so it can make good decisions. Two strategies:\n",
    "1. Prompt the sub-agent: Specify exactly what should be returned. A common failure mode is that the sub-agent performs tool calls or reasoning but doesn’t include results in its final message—remind it that the supervisor only sees the final output.\n",
    "2. Format in code: Adjust or enrich the response before returning it. For example, pass specific state keys back in addition to the final text using a Command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d95fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain.agents import AgentState\n",
    "from langchain.tools import InjectedToolCallId\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"subagent1_name\",\n",
    "    description=\"subagent1_description\"\n",
    ")\n",
    "def call_subagent1(\n",
    "    query: str,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> Command:\n",
    "    result = subagent1.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    })\n",
    "    return Command(update={\n",
    "        # Pass back additional state from the subagent\n",
    "        \"example_state_key\": result[\"example_state_key\"],\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=result[\"messages\"][-1].content,\n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5e205",
   "metadata": {},
   "source": [
    "## Handoffs\n",
    "\n",
    "In the handoffs architecture, behavior changes dynamically based on state. The core mechanism: tools update a state variable (e.g., current_step or active_agent) that persists across turns, and the system reads this variable to adjust behavior—either applying different configuration (system prompt, tools) or routing to a different agent. This pattern supports both handoffs between distinct agents and dynamic configuration changes within a single agent.\n",
    "\n",
    "Use the handoffs pattern when you need to enforce sequential constraints (unlock capabilities only after preconditions are met), the agent needs to converse directly with the user across different states, or you’re building multi-stage conversational flows. This pattern is particularly valuable for customer support scenarios where you need to collect information in a specific sequence — for example, collecting a warranty ID before processing a refund.\n",
    "\n",
    "The core mechanism is a tool that returns a Command to update state, triggering a transition to a new step or agent.\n",
    "\n",
    "There are two ways to implement handoffs: \n",
    "1. single agent with middleware (one agent with dynamic configuration): A single agent changes its behavior based on state. Middleware intercepts each model call and dynamically adjusts the system prompt and available tools. Tools update the state variable to trigger transitions:\n",
    "2. multiple agent subgraphs (distinct agents as graph nodes): Multiple distinct agents exist as separate nodes in a graph. Handoff tools navigate between agent nodes using Command.PARENT to specify which node to execute next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1897da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single agent with middleware\n",
    "\n",
    "from langchain.agents import AgentState, create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.messages import ToolMessage\n",
    "from langgraph.types import Command\n",
    "from typing import Callable\n",
    "\n",
    "# 1. Define state with current_step tracker\n",
    "class SupportState(AgentState):  \n",
    "    \"\"\"Track which step is currently active.\"\"\"\n",
    "    current_step: str = \"triage\"\n",
    "    warranty_status: str | None = None\n",
    "\n",
    "# 2. Tools update current_step via Command\n",
    "@tool\n",
    "def record_warranty_status(\n",
    "    status: str,\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> Command:  \n",
    "    \"\"\"Record warranty status and transition to next step.\"\"\"\n",
    "    return Command(update={  \n",
    "        \"messages\": [  \n",
    "            ToolMessage(\n",
    "                content=f\"Warranty status recorded: {status}\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ],\n",
    "        \"warranty_status\": status,\n",
    "        # Transition to next step\n",
    "        \"current_step\": \"specialist\"\n",
    "    })\n",
    "\n",
    "# 3. Middleware applies dynamic configuration based on current_step\n",
    "@wrap_model_call\n",
    "def apply_step_config(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Configure agent behavior based on current_step.\"\"\"\n",
    "    step = request.state.get(\"current_step\", \"triage\")  \n",
    "\n",
    "    # Map steps to their configurations\n",
    "    configs = {\n",
    "        \"triage\": {\n",
    "            \"prompt\": \"Collect warranty information...\",\n",
    "            \"tools\": [record_warranty_status]\n",
    "        },\n",
    "        \"specialist\": {\n",
    "            \"prompt\": \"Provide solutions based on warranty: {warranty_status}\",\n",
    "            \"tools\": [provide_solution, escalate]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    config = configs[step]\n",
    "    request = request.override(  \n",
    "        system_prompt=config[\"prompt\"].format(**request.state),  \n",
    "        tools=config[\"tools\"]  \n",
    "    )\n",
    "    return handler(request)\n",
    "\n",
    "# 4. Create agent with middleware\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[record_warranty_status, provide_solution, escalate],\n",
    "    state_schema=SupportState,\n",
    "    middleware=[apply_step_config],  \n",
    "    checkpointer=InMemorySaver()  # Persist state across turns  #\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c74475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple agent subgraphs\n",
    "from typing import Literal\n",
    "\n",
    "from langchain.agents import AgentState, create_agent\n",
    "from langchain.messages import AIMessage, ToolMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from typing_extensions import NotRequired\n",
    "\n",
    "\n",
    "# 1. Define state with active_agent tracker\n",
    "class MultiAgentState(AgentState):\n",
    "    active_agent: NotRequired[str]\n",
    "\n",
    "\n",
    "# 2. Create handoff tools\n",
    "@tool\n",
    "def transfer_to_sales(\n",
    "    runtime: ToolRuntime,\n",
    ") -> Command:\n",
    "    \"\"\"Transfer to the sales agent.\"\"\"\n",
    "    last_ai_message = next(  \n",
    "        msg for msg in reversed(runtime.state[\"messages\"]) if isinstance(msg, AIMessage)  \n",
    "    )  \n",
    "    transfer_message = ToolMessage(  \n",
    "        content=\"Transferred to sales agent from support agent\",  \n",
    "        tool_call_id=runtime.tool_call_id,  \n",
    "    )  \n",
    "    return Command(\n",
    "        goto=\"sales_agent\",\n",
    "        update={\n",
    "            \"active_agent\": \"sales_agent\",\n",
    "            \"messages\": [last_ai_message, transfer_message],  \n",
    "        },\n",
    "        graph=Command.PARENT,\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def transfer_to_support(\n",
    "    runtime: ToolRuntime,\n",
    ") -> Command:\n",
    "    \"\"\"Transfer to the support agent.\"\"\"\n",
    "    last_ai_message = next(  \n",
    "        msg for msg in reversed(runtime.state[\"messages\"]) if isinstance(msg, AIMessage)  \n",
    "    )  \n",
    "    transfer_message = ToolMessage(  \n",
    "        content=\"Transferred to support agent from sales agent\",  \n",
    "        tool_call_id=runtime.tool_call_id,  \n",
    "    )  \n",
    "    return Command(\n",
    "        goto=\"support_agent\",\n",
    "        update={\n",
    "            \"active_agent\": \"support_agent\",\n",
    "            \"messages\": [last_ai_message, transfer_message],  \n",
    "        },\n",
    "        graph=Command.PARENT,\n",
    "    )\n",
    "\n",
    "\n",
    "# 3. Create agents with handoff tools\n",
    "sales_agent = create_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    tools=[transfer_to_support],\n",
    "    system_prompt=\"You are a sales agent. Help with sales inquiries. If asked about technical issues or support, transfer to the support agent.\",\n",
    ")\n",
    "\n",
    "support_agent = create_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    tools=[transfer_to_sales],\n",
    "    system_prompt=\"You are a support agent. Help with technical issues. If asked about pricing or purchasing, transfer to the sales agent.\",\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Create agent nodes that invoke the agents\n",
    "def call_sales_agent(state: MultiAgentState) -> Command:\n",
    "    \"\"\"Node that calls the sales agent.\"\"\"\n",
    "    response = sales_agent.invoke(state)\n",
    "    return response\n",
    "\n",
    "\n",
    "def call_support_agent(state: MultiAgentState) -> Command:\n",
    "    \"\"\"Node that calls the support agent.\"\"\"\n",
    "    response = support_agent.invoke(state)\n",
    "    return response\n",
    "\n",
    "\n",
    "# 5. Create router that checks if we should end or continue\n",
    "def route_after_agent(\n",
    "    state: MultiAgentState,\n",
    ") -> Literal[\"sales_agent\", \"support_agent\", \"__end__\"]:\n",
    "    \"\"\"Route based on active_agent, or END if the agent finished without handoff.\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Check the last message - if it's an AIMessage without tool calls, we're done\n",
    "    if messages:\n",
    "        last_msg = messages[-1]\n",
    "        if isinstance(last_msg, AIMessage) and not last_msg.tool_calls:  \n",
    "            return \"__end__\"\n",
    "\n",
    "    # Otherwise route to the active agent\n",
    "    active = state.get(\"active_agent\", \"sales_agent\")\n",
    "    return active if active else \"sales_agent\"\n",
    "\n",
    "\n",
    "def route_initial(\n",
    "    state: MultiAgentState,\n",
    ") -> Literal[\"sales_agent\", \"support_agent\"]:\n",
    "    \"\"\"Route to the active agent based on state, default to sales agent.\"\"\"\n",
    "    return state.get(\"active_agent\") or \"sales_agent\"\n",
    "\n",
    "\n",
    "# 6. Build the graph\n",
    "builder = StateGraph(MultiAgentState)\n",
    "builder.add_node(\"sales_agent\", call_sales_agent)\n",
    "builder.add_node(\"support_agent\", call_support_agent)\n",
    "\n",
    "# Start with conditional routing based on initial active_agent\n",
    "builder.add_conditional_edges(START, route_initial, [\"sales_agent\", \"support_agent\"])\n",
    "\n",
    "# After each agent, check if we should end or route to another agent\n",
    "builder.add_conditional_edges(\n",
    "    \"sales_agent\", route_after_agent, [\"sales_agent\", \"support_agent\", END]\n",
    ")\n",
    "builder.add_conditional_edges(\n",
    "    \"support_agent\", route_after_agent, [\"sales_agent\", \"support_agent\", END]\n",
    ")\n",
    "\n",
    "graph = builder.compile()\n",
    "result = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hi, I'm having trouble with my account login. Can you help?\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a08e38",
   "metadata": {},
   "source": [
    "## Skills \n",
    "In the skills architecture, specialized capabilities are packaged as invokable “skills” that augment an agent’s behavior. Skills are primarily prompt-driven specializations that an agent can invoke on-demand.\n",
    "\n",
    "Use the skills pattern when you want a single agent with many possible specializations, you don’t need to enforce specific constraints between skills, or different teams need to develop capabilities independently. Common examples include coding assistants (skills for different languages or tasks), knowledge bases (skills for different domains), and creative assistants (skills for different formats).\n",
    "\n",
    "Key characteristics\n",
    "1. Prompt-driven specialization: Skills are primarily defined by specialized prompts\n",
    "2. Progressive disclosure: Skills become available based on context or user needs\n",
    "3. Team distribution: Different teams can develop and maintain skills independently\n",
    "4. Lightweight composition: Skills are simpler than full sub-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@tool\n",
    "def load_skill(skill_name: str) -> str:\n",
    "    \"\"\"Load a specialized skill prompt.\n",
    "\n",
    "    Available skills:\n",
    "    - write_sql: SQL query writing expert\n",
    "    - review_legal_doc: Legal document reviewer\n",
    "\n",
    "    Returns the skill's prompt and context.\n",
    "    \"\"\"\n",
    "    # Load skill content from file/database\n",
    "    ...\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[load_skill],\n",
    "    system_prompt=(\n",
    "        \"You are a helpful assistant. \"\n",
    "        \"You have access to two skills: \"\n",
    "        \"write_sql and review_legal_doc. \"\n",
    "        \"Use load_skill to access them.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30348d",
   "metadata": {},
   "source": [
    "## Routers\n",
    "In the router architecture, a routing step classifies input and directs it to specialized agents. This is useful when you have distinct verticals—separate knowledge domains that each require their own agent.\n",
    "\n",
    "Use the router pattern when you have distinct verticals (separate knowledge domains that each require their own agent), need to query multiple sources in parallel, and want to synthesize results into a combined response.\n",
    "\n",
    "The router classifies the query and directs it to the appropriate agent(s). \n",
    "1. Use Command for single-agent routing \n",
    "2. Send for parallel fan-out to multiple agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single agent Routing\n",
    "from langgraph.types import Command\n",
    "\n",
    "def classify_query(query: str) -> str:\n",
    "    \"\"\"Use LLM to classify query and determine the appropriate agent.\"\"\"\n",
    "    # Classification logic here\n",
    "    ...\n",
    "\n",
    "def route_query(state: State) -> Command:\n",
    "    \"\"\"Route to the appropriate agent based on query classification.\"\"\"\n",
    "    active_agent = classify_query(state[\"query\"])\n",
    "\n",
    "    # Route to the selected agent\n",
    "    return Command(goto=active_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abefd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Agent Routing\n",
    "from typing import TypedDict\n",
    "from langgraph.types import Send\n",
    "\n",
    "class ClassificationResult(TypedDict):\n",
    "    query: str\n",
    "    agent: str\n",
    "\n",
    "def classify_query(query: str) -> list[ClassificationResult]:\n",
    "    \"\"\"Use LLM to classify query and determine which agents to invoke.\"\"\"\n",
    "    # Classification logic here\n",
    "    ...\n",
    "\n",
    "def route_query(state: State):\n",
    "    \"\"\"Route to relevant agents based on query classification.\"\"\"\n",
    "    classifications = classify_query(state[\"query\"])\n",
    "\n",
    "    # Fan out to selected agents in parallel\n",
    "    return [\n",
    "        Send(c[\"agent\"], {\"query\": c[\"query\"]})\n",
    "        for c in classifications\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6afd9a",
   "metadata": {},
   "source": [
    "### Routers Vs Subagents\n",
    "\n",
    "Router vs. Subagents: Both patterns can dispatch work to multiple agents, but they differ in how routing decisions are made:\n",
    "1. Router: A dedicated routing step (often a single LLM call or rule-based logic) that classifies the input and dispatches to agents. The router itself typically doesn’t maintain conversation history or perform multi-turn orchestration—it’s a preprocessing step.\n",
    "2. Subagents: An main supervisor agent dynamically decides which subagents to call as part of an ongoing conversation. The main agent maintains context, can call multiple subagents across turns, and orchestrates complex multi-step workflows.\n",
    "\n",
    "Use a router when you have clear input categories and want deterministic or lightweight classification. Use a supervisor when you need flexible, conversation-aware orchestration where the LLM decides what to do next based on evolving context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c5d6b",
   "metadata": {},
   "source": [
    "# Custom Workflow\n",
    "\n",
    "In the custom workflow architecture, you define your own bespoke execution flow using LangGraph. You have complete control over the graph structure—including sequential steps, conditional branches, loops, and parallel execution.\n",
    "\n",
    "Use custom workflows when standard patterns (subagents, skills, etc.) don’t fit your requirements, you need to mix deterministic logic with agentic behavior, or your use case requires complex routing or multi-stage processing.\n",
    "\n",
    "Each node in your workflow can be a simple function, an LLM call, or an entire agent with tools. You can also compose other architectures within a custom workflow—for example, embedding a multi-agent system as a single node."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
