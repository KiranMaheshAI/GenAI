{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Splitting from Documents- RecursiveCharacter Text Splitters\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. \n",
    "It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. \n",
    "This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, \n",
    "as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "- How the text is split: by list of characters.\n",
    "- How the chunk size is measured: by number of characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"../data/sample.pdf\")\n",
    "pdf_document = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(pdf_document)\n",
    "print(texts[0].page_content)\n",
    "print(\"-----\")\n",
    "print(texts[1].page_content)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 167, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is specially used for LLM powered applications.\n",
      "-----\n",
      "Langchain  -> Chaining  -> Focus on Sequential Execution of process\n",
      "* In Langchain, everything happens in sequential order So we call it as Directed Acyclic Graph(DAG)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from json import load\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/sample.txt\")\n",
    "text_document = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(text_document)\n",
    "print(texts[0].page_content)\n",
    "print(\"-----\")\n",
    "print(texts[1].page_content)\n",
    "print(\"-----\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to split by HTML header\n",
    "HTMLHeaderTextSplitter is a \"structure-aware\" chunker that splits text at the HTML element level and adds metadata for each header \"relevant\" to any given chunk. It can return chunks element by element or combine elements with the same metadata, with the objectives of (a) keeping related text grouped (more or less) semantically and (b) preserving context-rich information encoded in document structures. It can be used with other text splitters as part of a chunking pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Foo'}, page_content='Foo'),\n",
       " Document(metadata={'Header 1': 'Foo'}, page_content='Some intro text about Foo.'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section'}, page_content='Bar main section'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section'}, page_content='Some intro text about Bar.'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 1'}, page_content='Bar subsection 1'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 1'}, page_content='Some text about the first subtopic of Bar.'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 2'}, page_content='Bar subsection 2'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 2'}, page_content='Some text about the second subtopic of Bar.'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Baz'}, page_content='Baz'),\n",
       " Document(metadata={'Header 1': 'Foo'}, page_content='Some text about Baz  \\nSome concluding text about Foo')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Foo</h1>\n",
    "        <p>Some intro text about Foo.</p>\n",
    "        <div>\n",
    "            <h2>Bar main section</h2>\n",
    "            <p>Some intro text about Bar.</p>\n",
    "            <h3>Bar subsection 1</h3>\n",
    "            <p>Some text about the first subtopic of Bar.</p>\n",
    "            <h3>Bar subsection 2</h3>\n",
    "            <p>Some text about the second subtopic of Bar.</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Baz</h2>\n",
    "            <p>Some text about Baz</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Some concluding text about Foo</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to split JSON data\n",
    "This json splitter splits json data while allowing control over chunk sizes. It traverses json data depth first and builds smaller json chunks. It attempts to keep nested json objects whole but will split them if needed to keep chunks between a min_chunk_size and the max_chunk_size.\n",
    "\n",
    "If the value is not a nested json, but rather a very large string the string will not be split. If you need a hard cap on the chunk size consider composing this with a Recursive Text splitter on those chunks. There is an optional pre-processing step to split lists, by first converting them to json (dict) and then splitting them as such.\n",
    "\n",
    "- How the text is split: json value.\n",
    "- How the chunk size is measured: by number of characters.\n",
    "\n",
    "Ref: https://python.langchain.com/docs/how_to/recursive_json_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openapi': '3.1.0', 'info': {'title': 'LangSmith', 'version': '0.1.0'}, 'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'tags': ['tracer-sessions'], 'summary': 'Get Tracing Project Prebuilt Dashboard', 'description': 'Get a prebuilt dashboard for a tracing project.'}}}}\n",
      "-----\n",
      "{'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'operationId': 'get_tracing_project_prebuilt_dashboard_api_v1_sessions__session_id__dashboard_post', 'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}}\n",
      "-----\n",
      "{'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'parameters': [{'name': 'session_id', 'in': 'path', 'required': True, 'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}, {'name': 'accept', 'in': 'header', 'required': False, 'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Accept'}}]}}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "json_data=requests.get(\"https://api.smith.langchain.com/openapi.json\").json()\n",
    "json_splitter=RecursiveJsonSplitter(max_chunk_size=300)\n",
    "json_chunks=json_splitter.split_json(json_data)\n",
    "print(json_chunks[0])\n",
    "print(\"-----\")\n",
    "print(json_chunks[1])\n",
    "print(\"-----\")\n",
    "print(json_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}/dashboard\": {\"post\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Get Tracing Project Prebuilt Dashboard\", \"description\": \"Get a prebuilt dashboard for a tracing project.\"}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}/dashboard\": {\"post\": {\"operationId\": \"get_tracing_project_prebuilt_dashboard_api_v1_sessions__session_id__dashboard_post\", \"security\": [{\"API Key\": []}, {\"Tenant ID\": []}, {\"Bearer Auth\": []}]}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}/dashboard\": {\"post\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}'\n"
     ]
    }
   ],
   "source": [
    "# for getting documents from json data\n",
    "docs = json_splitter.create_documents(texts=[json_data])\n",
    "\n",
    "for doc in docs[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Similarity Text Splitter\n",
    "At a high level, this splits into sentences, then groups into groups of 3 sentences, and then merges one that are similar in the embedding space.\n",
    "\n",
    "Ref: https://python.langchain.com/docs/how_to/semantic-chunker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\" AAPL Stock Analysis - Initial Findings:\\nAverage analyst rating: Buy\\n12-month average price target: $237.36\\nPotential upside from current price (approx. $196.58): +20.75%\\nAnalyst Opinions and Sentiment (from Yahoo Finance):\\nStrong Buy, Buy, Hold, Underperform, Sell ratings are present. Earnings Per Share (EPS) estimates for current and next quarters/years are\\navailable. Revenue estimates for current and next quarters/years are available. Sales Growth (year/est) is positive for current and next years. Several top analysts have 'Outperform' or 'Strong Buy' ratings with price targets\\nranging from $230 to $300. Recent Company Developments and Financial Performance (from Apple's Q2 2025 \\nearnings report):\\nQ2 2025 revenue: $95.4 billion, up 5% year over year. Q2 2025 diluted earnings per share: $1.65, up 8% year over year. Double-digit growth in Services.\"),\n",
       " Document(metadata={}, page_content='Introduced iPhone 16e, new Macs, and iPads. Cut carbon emissions by 60% over the past decade. $24 billion in operating cash flow. Returned $29 billion to shareholders. Installed base of active devices reached a new all-time high. Board declared a cash dividend of $0.26 per share (4% increase). Authorized an additional program to repurchase up to $100 billion of common\\nstock. • \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n•')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text_splitter = SemanticChunker(embeddings)\n",
    "loader = PyPDFLoader(\"../data/sample.pdf\")\n",
    "pdf_document = loader.load()\n",
    "doc_data = \" \"\n",
    "for doc in pdf_document:\n",
    "    doc_data += doc.page_content\n",
    "texts = text_splitter.create_documents([doc_data])\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default way to split is based on percentile. In this method, all differences between sentences are calculated, \n",
    "and then any difference greater than the X percentile is split. \n",
    "The default value for X is 95.0 and can be adjusted by the keyword argument breakpoint_threshold_amount which expects a number between 0.0 and 100.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AAPL Stock Analysis - Initial Findings:\n",
      "Average analyst rating: Buy\n",
      "12-month average price target: $237.36\n",
      "Potential upside from current price (approx. $196.58): +20.75%\n",
      "Analyst Opinions and Sentiment (from Yahoo Finance):\n",
      "Strong Buy, Buy, Hold, Underperform, Sell ratings are present. Earnings Per Share (EPS) estimates for current and next quarters/years are\n",
      "available. Revenue estimates for current and next quarters/years are available. Sales Growth (year/est) is positive for current and next years. Several top analysts have 'Outperform' or 'Strong Buy' ratings with price targets\n",
      "ranging from $230 to $300. Recent Company Developments and Financial Performance (from Apple's Q2 2025 \n",
      "earnings report):\n",
      "Q2 2025 revenue: $95.4 billion, up 5% year over year. Q2 2025 diluted earnings per share: $1.65, up 8% year over year. Double-digit growth in Services.\n",
      "-----\n",
      "2\n",
      "-----\n",
      " AAPL Stock Analysis - Initial Findings:\n",
      "Average analyst rating: Buy\n",
      "12-month average price target: $237.36\n",
      "Potential upside from current price (approx. $196.58): +20.75%\n",
      "Analyst Opinions and Sentiment (from Yahoo Finance):\n",
      "Strong Buy, Buy, Hold, Underperform, Sell ratings are present. Earnings Per Share (EPS) estimates for current and next quarters/years are\n",
      "available. Revenue estimates for current and next quarters/years are available.\n",
      "-----\n",
      "Sales Growth (year/est) is positive for current and next years. Several top analysts have 'Outperform' or 'Strong Buy' ratings with price targets\n",
      "ranging from $230 to $300. Recent Company Developments and Financial Performance (from Apple's Q2 2025 \n",
      "earnings report):\n",
      "Q2 2025 revenue: $95.4 billion, up 5% year over year. Q2 2025 diluted earnings per share: $1.65, up 8% year over year. Double-digit growth in Services.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    embeddings, breakpoint_threshold_type=\"percentile\", min_chunk_size=100, \n",
    ")\n",
    "\n",
    "docs = text_splitter.create_documents([doc_data])\n",
    "print(docs[0].page_content)\n",
    "print(\"-----\")\n",
    "print(len(docs))\n",
    "print(\"-----\")\n",
    "\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(texts[0].page_content)\n",
    "print(\"-----\")\n",
    "print(texts[1].page_content)\n",
    "print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
