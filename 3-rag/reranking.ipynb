{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c7c910",
   "metadata": {},
   "source": [
    "### ReRanking\n",
    "\n",
    "Reranking is a two-stage search process that first retrieves a set of candidate documents and then uses a more sophisticated model to reorder them based on deeper semantic relevance. \n",
    "\n",
    "Once the documents are retrieved from the Vector database, we are again reranking the documents for improving the relevance and reducing the Noise and Improve efficiency.\n",
    "\n",
    "The intuition behind a bi-encoder's inferior accuracy is that bi-encoders must compress all of the possible meanings of a document into a single vector — meaning we lose information. Additionally, bi-encoders have no context on the query because we don't know the query until we receive it (we create embeddings before user query time).\n",
    "\n",
    "On the other hand, a reranker can receive the raw information directly into the large transformer computation, meaning less information loss. Because we are running the reranker at user query time, we have the added benefit of analyzing our document's meaning specific to the user query — rather than trying to produce a generic, averaged meaning.\n",
    "\n",
    "Rerankers avoid the information loss of bi-encoders — but they come with a different penalty — time.\n",
    "\n",
    "Ref: https://medium.com/@sujathamudadla1213/bi-encoder-vs-cross-encoder-when-to-use-which-one-4a20edbe6d37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d524c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Why reranking is important\n",
    "\n",
    "##### Improves accuracy: \n",
    "It goes beyond the limitations of a single embedding by evaluating the relevance of the query and document in tandem, leading to more accurate results. \n",
    "##### Handles semantic ambiguity: \n",
    "Reranking can better distinguish between different meanings of words or phrases in a query, leading to more precise results than initial retrieval alone might provide. For example, a search for \"install Python\" can be disambiguated from \"Python snake habitats\" by a reranker. \n",
    "##### Enhances RAG systems: \n",
    "By ensuring the best information is passed to a large language model, reranking significantly improves the quality and accuracy of the model's responses. \n",
    "##### Increases efficiency: \n",
    "It's a cost-effective way to improve results because it applies expensive, sophisticated models to a smaller subset of documents, rather than the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ab1900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154319c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\"\n",
    "model = SentenceTransformer(model_name)\n",
    "sentences = [\"The weather is lovely today.\", \" It's so sunny outside!\"]\n",
    "document_embeddings = model.encode(sentences)\n",
    "len(document_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "232d4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the weather in Tokyo?\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "# Compute dot product between query and document embeddings\n",
    "# dot_product = np.dot(query_embedding, document_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "259a2a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23531786, 0.23735909]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between query and document embeddings\n",
    "# Reshape query_embedding to 2D array (1 sample, n features)\n",
    "similarity_scores = cosine_similarity(query_embedding.reshape(1, -1), document_embeddings)\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d96653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's so sunny outside!\n"
     ]
    }
   ],
   "source": [
    "most_similar_index = np.argmax(similarity_scores)\n",
    "most_similar_document = sentences[most_similar_index]\n",
    "print(most_similar_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43200ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\" It's so sunny outside!\", 0.23735909), ('The weather is lovely today.', 0.23531786)]\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(similarity_scores[0])[::-1]\n",
    "ranked_documents = [(sentences[i], similarity_scores[0][i]) for i in sorted_indices]\n",
    "print(ranked_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15c90f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Documents: \n",
      "1. Document:  It's so sunny outside!, Score: 0.2374\n",
      "2. Document: The weather is lovely today., Score: 0.2353\n"
     ]
    }
   ],
   "source": [
    "print(\"Ranked Documents: \")\n",
    "for rank, (doc, score) in enumerate(ranked_documents, start=1):\n",
    "    print(f\"{rank}. Document: {doc}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8553e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Documents: \n",
      "1. Document:  It's so sunny outside!, Score: 0.2374\n",
      "2. Document: The weather is lovely today., Score: 0.2353\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 2 Documents: \")\n",
    "for rank, (doc, score) in enumerate(ranked_documents[:2], start=1):\n",
    "    print(f\"{rank}. Document: {doc}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2946ff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b139d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "top_2_documents = [doc for doc, _ in ranked_documents[:2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbb705b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"It's\", 'so', 'sunny', 'outside!'],\n",
       " ['The', 'weather', 'is', 'lovely', 'today.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_top_2_docs = [doc.split() for doc in top_2_documents]\n",
    "tokenized_top_2_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "920c1fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How', 'is', 'the', 'weather', 'today?']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How is the weather today?\"\n",
    "tokenized_query = query.split()\n",
    "tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f50495f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Okapi(tokenized_top_2_docs)\n",
    "\n",
    "# Compute BM25 scores for the query\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Get the top 2 documents with highest BM25 scores\n",
    "bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b082cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The weather is lovely today.', 0.0), (\" It's so sunny outside!\", 0.0)]\n",
      "Ranked Documents: \n",
      "1. Document: The weather is lovely today., Score: 0.0000\n",
      "2. Document:  It's so sunny outside!, Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(bm25_scores)[::-1]\n",
    "ranked_documents = [(top_2_documents[i], bm25_scores[i]) for i in sorted_indices]\n",
    "print(ranked_documents)\n",
    "\n",
    "print(\"Ranked Documents: \")\n",
    "for rank, (doc, score) in enumerate(ranked_documents, start=1):\n",
    "    print(f\"{rank}. Document: {doc}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696a3f0",
   "metadata": {},
   "source": [
    "### Using Cross Encoder\n",
    "\n",
    "The input of the model always consists of a data pair, for example two sentences, one is query and other is document, the outputs a value between 0 and 1 indicating the similarity score between two sentences.\n",
    "\n",
    "Ref: https://sbert.net/examples/cross_encoder/applications/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6937659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.511463 , -4.9981213,  1.7217119], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "query = \"What is the weather in Tokyo?\"\n",
    "document = [\"The weather is lovely today in tokyo and its sunny too.\", \"The weather is lovely today in mumbai and its sunny too.\", \"The weather is lovely today in japan.\"]\n",
    "pairs = [[query, doc] for doc in document]\n",
    "scores = model.predict(pairs)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd89a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7.511463, 'The weather is lovely today in tokyo and its sunny too.'),\n",
       " (1.7217119, 'The weather is lovely today in japan.'),\n",
       " (-4.9981213, 'The weather is lovely today in mumbai and its sunny too.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_docs = zip(scores, document)\n",
    "reranked_docs = sorted(scored_docs, key=lambda x: x[0], reverse=True)\n",
    "reranked_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fb1d5",
   "metadata": {},
   "source": [
    "### Cohere API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a10cab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Downloading cohere-5.20.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Downloading fastavro-1.12.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (2.33.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (0.21.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (2.32.4.20250913)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from cohere) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2025.6.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from tokenizers<1,>=0.15->cohere) (0.33.0)\n",
      "Requirement already satisfied: filelock in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.4)\n",
      "Requirement already satisfied: anyio in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from pydantic>=1.9.2->cohere) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/I572648/Library/CloudStorage/OneDrive-SAPSE/Desktop/Git/GenAI/.venv/lib/python3.11/site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
      "Downloading cohere-5.20.0-py3-none-any.whl (303 kB)\n",
      "Downloading fastavro-1.12.1-cp311-cp311-macosx_10_9_universal2.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastavro, cohere\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [cohere]2m1/2\u001b[0m [cohere]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cohere-5.20.0 fastavro-1.12.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ff9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.Client('YOUR_API_KEY')\n",
    "\n",
    "response = co.rerank(\n",
    "    model='rerank-english-v3.0',\n",
    "    query=\"What is the capital of France?\",\n",
    "    documents=[\"Paris is the capital of France.\", \"Paris is the capital of France.\", \"Paris is the capital of France.\"],\n",
    "    top_n=2,\n",
    "    return_documents=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
