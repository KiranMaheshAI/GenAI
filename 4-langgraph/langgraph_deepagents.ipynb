{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69da3f42",
   "metadata": {},
   "source": [
    "### DeepAgents\n",
    "\n",
    "DeepAgents are generally capable of planning more complex tasks, and then executing over longer time horizons on those goals. The difference compared to the naive agent that is easy to build is:\n",
    "\n",
    "1. A detailed system prompt\n",
    "2. Planning tool\n",
    "3. Sub agents\n",
    "4. File system\n",
    "\n",
    "Ref: https://github.com/langchain-ai/deepagents?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install deepagents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e11aa",
   "metadata": {},
   "source": [
    "`deepagents` uses Anthropic's Claude by default, but no `ANTHROPIC_API_KEY` is set. We can fix this by explicitly passing an OpenAI model to `create_deep_agent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdefe445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is langgraph?', additional_kwargs={}, response_metadata={}, id='ad5fc976-b832-4dad-814c-4e101bdbffca'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lziNFqh22Fe3eE5VvdH3ExZZ', 'function': {'arguments': '{\"query\":\"LangGraph\",\"max_results\":5}', 'name': 'internet_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 4039, 'total_tokens': 4059, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CTisCS0pwboN9fPDz7Fnl43ehLuO7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--fda18031-f06b-4231-bb11-76107a15f4ac-0', tool_calls=[{'name': 'internet_search', 'args': {'query': 'LangGraph', 'max_results': 5}, 'id': 'call_lziNFqh22Fe3eE5VvdH3ExZZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4039, 'output_tokens': 20, 'total_tokens': 4059, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"*   [Overview](https://www.ibm.com/think/topics/ai-agents#7281535) *   [Overview](https://www.ibm.com/think/topics/components-of-ai-agents#498277090) *   [Learning](https://www.ibm.com/think/topics/ai-agent-learning#498277087) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#1287801557) *   [Overview](https://www.ibm.com/think/topics/ai-agent-protocols#1509394340) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#80364620) *   [Overview](https://www.ibm.com/think/insights/ai-agent-governance#1268897081) *   [Overview](https://www.ibm.com/think/topics/ai-agent-use-cases#257779831) *   [Human resources](https://www.ibm.com/think/topics/ai-agents-in-human-resources#257779835) LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an [AI agent workflow](https://www.ibm.com/think/topics/ai-agents). LangGraph is also built on several key technologies, including [LangChain,](https://www.ibm.com/think/topics/langchain) a Python framework for building AI applications. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including [chatbots](https://www.ibm.com/think/topics/chatbots), state graphs and [other agent-based systems](https://www.ibm.com/think/topics/multiagent-system).\", \"score\": 0.93425745, \"raw_content\": null}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"content\": \"# pip install -qU \\\\\"langchain[anthropic]\\\\\" to call the model from langgraph prebuilt import create_react_agent def get_weather city str -> str\\\\\"\\\\\"\\\\\"Get weather for a given city.\\\\\"\\\\\"\\\\\" returnf\\\\\"It\\'s always sunny in {city}!\\\\\"{city}{city} agent = create_react_agent model =\\\\\"anthropic:claude-3-7-sonnet-latest\\\\\" tools = get_weather prompt = \\\\\"You are a helpful assistant\\\\\" # Run the agent agent invoke \\\\\"messages\\\\\" \\\\\"role\\\\\" \\\\\"user\\\\\" \\\\\"content\\\\\" \\\\\"what is the weather in sf\\\\\" Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials. LangGraph provides low-level supporting infrastructure for *any* long-running, stateful workflow or agent. While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents.\", \"score\": 0.83452857, \"raw_content\": null}, {\"url\": \"https://langchain-ai.github.io/langgraph/concepts/why-langgraph/\", \"title\": \"Learn LangGraph basics - Overview\", \"content\": \"* Learn LangGraph basics LangGraph is built for developers who want to build powerful, adaptable AI agents. * **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course. * **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time. To get acquainted with LangGraph\\'s key concepts and features, complete the following LangGraph basics tutorials series: 4. Add human-in-the-loop controls In completing this series of tutorials, you will build a support chatbot in LangGraph that can: * ✅ **Maintain conversation state** across calls * ✅ **Use custom state** to control its behavior\", \"score\": 0.76554126, \"raw_content\": null}, {\"url\": \"https://www.langchain.com/langgraph\", \"title\": \"LangGraph - LangChain\", \"content\": \"[![Image 3](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e27023585643370a6471_icons.svg) LangChain Quick start agents with any model provider](https://www.langchain.com/langchain)[![Image 4](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e270417338c7f027082d_d035ce400e48f9bc4dd0578d0e3e3211_icons-1.svg) LangGraph Build custom agents with low-level control](https://www.langchain.com/langgraph)[![Image 5](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68f20863b71dbae1af829979_DeepAgents.svg) Deep Agents New Use planning, memory, and sub-agents for complex, long-running tasks](https://github.com/langchain-ai/deepagents) [![Image 6](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e270df09334914882b88_Frame%209.svg) Observability Debug and monitor in-depth traces](https://www.langchain.com/langsmith/observability)[![Image 7](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e270f9e8de1d368764a8_Frame%20206.svg) Evaluation Iterate on prompts and models](https://www.langchain.com/langsmith/evaluation)[![Image 8](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e2709eef27fc61465416_Frame%20100039.svg) Deployment Ship and scale agents in production](https://www.langchain.com/langsmith/deployment) [See LangGraph use cases in production](https://www.langchain.com/built-with-langgraph) ![Image 11](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg) ![Image 12](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 15](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/681b568070e9f341ed73b877_logo_Cisco.svg) ![Image 17](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 21](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg) ![Image 22](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 25](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/681b568070e9f341ed73b877_logo_Cisco.svg) ![Image 27](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 32](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 37](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 42](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 47](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 50](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b080e4b3ca12dc5d5d439_Langgraph%20UI-2.webp) [Read a conceptual guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop) ![Image 52](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68663ca715b9bd5d707bee71_Modified-Human-in-the-loop_white.gif) ![Image 53](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6865b895f061b6f892568ff6_Modified-Customizable-Agent-Architectures_white.gif) [See different agent architectures](https://docs.langchain.com/oss/python/langgraph/workflows-agents) [Learn about agent memory](https://docs.langchain.com/oss/python/langgraph/add-memory) ![Image 55](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6865b8b7df5aea00af3a4554_Modified-Streaming-intermediate-steps_white.gif) [![Image 58](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/678e35d6c553c4fb20f9b753_Frame%2099644.webp)![Image 59](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6787ae0bce5c99dd808545ce_card%202.webp)](https://academy.langchain.com/courses/intro-to-langgraph) ![Image 61](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp) ![Image 63](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp) ![Image 65](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png) ![Image 67](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp) ![Image 69](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp) ![Image 71](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png) ![Image 72](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c6a38f9c53ec71f5fc73de_langchain-word.svg)\", \"score\": 0.68723184, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=1w5cCXlh7JQ\", \"title\": \"LangGraph Tutorial - How to Build Advanced AI Agent Systems\", \"content\": \"LangGraph Tutorial - How to Build Advanced AI Agent Systems\\\\nTech With Tim\\\\n1880000 subscribers\\\\n3223 likes\\\\n141919 views\\\\n5 May 2025\\\\nDownload PyCharm and use it for free forever with one month of Pro included: https://www.jetbrains.com/pycharm/\\\\n\\\\nIn this video, you\\'re going to learn how to build AI agents using LangGraph. LangGraph is a much more professional and in-depth framework compared to something like LangChain or LlamaIndex, which allows you to build a really complicated and well thought out AI agents. If you\\'re looking to push something into production, you want to have scalability features, and overall you just want more control, then LangGraph is what you should be using.\\\\n\\\\n🚀 My Software Development Program: https://coursecareers.com/a/techwithtim?course=software-dev-fundamentals&campaign=youtubedescription\\\\n\\\\n📬 Join my Newsletter: https://techwithtim.net/newsletter\\\\n\\\\n🎓 Get private mentorship from me: https://training.techwithtim.net\\\\n\\\\n🎞 Video Resources 🎞\\\\nCode In This Video: https://github.com/techwithtim/LangGraph-Tutorial\\\\nUV Website: https://docs.astral.sh/uv/\\\\nUV Video: https://www.youtube.com/watch?v=6pttmsBSi8M&ab_channel=TechWithTim\\\\nAnthropic Console: https://console.anthropic.com/settings/keys\\\\nLangGraph Getting Started Guide: https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot\\\\n\\\\n⏳ Timestamps ⏳\\\\n00:00 | Overview\\\\n00:44 | LangGraph Core Features\\\\n02:31 | LangGraph Examples\\\\n04:20 | IDE Choice\\\\n05:00 | Environment Setup/Install\\\\n07:45 | Getting LLM API Token\\\\n08:59 | Simple LangGraph Chatbot\\\\n23:20 | Generating The Visual Graph\\\\n24:25 | Complex LangGraph Chatbot\\\\n\\\\nHashtags\\\\n#LangGraph #LangChain #AiAgents\\\\n87 comments\\\\n\", \"score\": 0.64773196, \"raw_content\": null}], \"response_time\": 0.98, \"request_id\": \"22264df3-e148-4bcc-a268-d57ebab19483\"}', name='internet_search', id='fef26a77-0698-4da6-920d-69be69a5844e', tool_call_id='call_lziNFqh22Fe3eE5VvdH3ExZZ'), AIMessage(content='LangGraph is an open-source AI agent framework designed to build, deploy, and manage complex generative AI agent workflows. It utilizes graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph is built on several key technologies, including LangChain, a Python framework for building AI applications. It provides a versatile platform for developing AI solutions and workflows, including chatbots, state graphs, and other agent-based systems. LangGraph supports long-running, stateful workflows and integrates seamlessly with LangChain products, offering tools for building resilient language agents with low-level control.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 121, 'prompt_tokens': 7411, 'total_tokens': 7532, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3968}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CTisHxwp9mbHBIpEwMnzesyOSv6RS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e8785877-0a72-43ff-a0e5-27f87a8ab0f9-0', usage_metadata={'input_tokens': 7411, 'output_tokens': 121, 'total_tokens': 7532, 'input_token_details': {'audio': 0, 'cache_read': 3968}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "from deepagents import create_deep_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "# Web search tool\n",
    "def internet_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = False,\n",
    "):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic,\n",
    "    )\n",
    "\n",
    "\n",
    "# System prompt to steer the agent to be an expert researcher\n",
    "research_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.\n",
    "\n",
    "You have access to an internet search tool as your primary means of gathering information.\n",
    "\n",
    "## `internet_search`\n",
    "\n",
    "Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n",
    "\"\"\"\n",
    "\n",
    "# Configure the model to use OpenAI instead of default Anthropic\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create the deep agent with OpenAI model\n",
    "agent = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=[internet_search],\n",
    "    system_prompt=research_instructions,\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langgraph?\"}]})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da26174",
   "metadata": {},
   "source": [
    "###create_deep_agent: \n",
    "The agent created with create_deep_agent is just a LangGraph graph - so you can interact with it (streaming, human-in-the-loop, memory, studio) in the same way you would any LangGraph agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040394c4",
   "metadata": {},
   "source": [
    "### SubAgents:\n",
    "\n",
    "A main feature of Deep Agents is their ability to spawn subagents. You can specify custom subagents that your agent can hand off work to in the subagents parameter. Sub agents are useful for context quarantine (to help not pollute the overall context of the main agent) as well as custom instructions.\n",
    "\n",
    "class SubAgent(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    prompt: str\n",
    "    tools: Sequence[BaseTool | Callable | dict[str, Any]]\n",
    "    model: NotRequired[str | BaseChatModel]\n",
    "    middleware: NotRequired[list[AgentMiddleware]]\n",
    "    interrupt_on: NotRequired[dict[str, bool | InterruptOnConfig]]\n",
    "\n",
    "class CompiledSubAgent(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    runnable: Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec7cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from tavily import TavilyClient\n",
    "from deepagents import create_deep_agent\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "def internet_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = False,\n",
    "):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic,\n",
    "    )\n",
    "\n",
    "research_subagent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Used to research more in depth questions\",\n",
    "    \"system_prompt\": \"You are a great researcher\",\n",
    "    \"tools\": [internet_search],\n",
    "    \"model\": \"openai:gpt-4o\",  # Optional override, defaults to main agent model\n",
    "}\n",
    "subagents = [research_subagent]\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    subagents=subagents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom agent graph\n",
    "custom_graph = create_agent(\n",
    "    model=your_model,\n",
    "    tools=specialized_tools,\n",
    "    prompt=\"You are a specialized agent for data analysis...\"\n",
    ")\n",
    "\n",
    "# Use it as a custom subagent\n",
    "custom_subagent = CompiledSubAgent(\n",
    "    name=\"data-analyzer\",\n",
    "    description=\"Specialized agent for complex data analysis tasks\",\n",
    "    runnable=custom_graph\n",
    ")\n",
    "\n",
    "subagents = [custom_subagent]\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    tools=[internet_search],\n",
    "    system_prompt=research_instructions,\n",
    "    subagents=subagents\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b4eeb",
   "metadata": {},
   "source": [
    "### middleware:\n",
    "\n",
    "create_deep_agent is implemented with middleware that can be customized. You can provide additional middleware to extend functionality, add tools, or implement custom hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df7a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from deepagents import create_deep_agent\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "@tool\n",
    "def get_temperature(city: str) -> str:\n",
    "    \"\"\"Get the temperature in a city.\"\"\"\n",
    "    return f\"The temperature in {city} is 70 degrees Fahrenheit.\"\n",
    "\n",
    "class WeatherMiddleware(AgentMiddleware):\n",
    "  tools = [get_weather, get_temperature]\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=model,\n",
    "    middleware=[WeatherMiddleware()]\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langgraph?\"}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212068f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is langgraph?', additional_kwargs={}, response_metadata={}, id='b0e18f99-4b96-4ad8-bda0-66caafcb9d3b'),\n",
       "  AIMessage(content='LangGraph is a framework designed to facilitate the creation of complex applications that leverage Large Language Models (LLMs). It provides a structured way to build applications by using a graph-based approach, where nodes represent different tasks or operations, and edges define the flow of data and control between these tasks. This allows developers to design applications that can perform a variety of functions, such as data processing, decision-making, and interaction with users, all orchestrated through the capabilities of LLMs. LangGraph aims to simplify the integration of LLMs into applications by providing tools and abstractions that manage the complexity of working with these models.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 3944, 'total_tokens': 4070, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'id': 'chatcmpl-CTiuRz9uBAnmhY0tyuv97iGOWStgl', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--96248227-d11a-4531-9cf5-582f03ee2b30-0', usage_metadata={'input_tokens': 3944, 'output_tokens': 126, 'total_tokens': 4070, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcc506",
   "metadata": {},
   "source": [
    "### Use_longterm_memory:\n",
    "\n",
    "Deep agents come with a local filesystem to offload memory to. This filesystem is stored in state, and is therefore transient to a single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents import create_deep_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()  # Or any other Store object\n",
    "agent = create_deep_agent(\n",
    "    store=store,\n",
    "    use_longterm_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d71f3b2",
   "metadata": {},
   "source": [
    "### interrupt_on\n",
    "\n",
    "A common reality for agents is that some tool operations may be sensitive and require human approval before execution. Deep Agents supports human-in-the-loop workflows through LangGraph’s interrupt capabilities. You can configure which tools require approval using a checkpointe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37acb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from deepagents import create_deep_agent\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    tools=[get_weather],\n",
    "    interrupt_on={\n",
    "        \"get_weather\": {\n",
    "            \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47e9cd",
   "metadata": {},
   "source": [
    "### Deep Agents Middleware\n",
    "When you create a deep agent with create_deep_agent, we automatically attach PlanningMiddleware, FilesystemMiddleware and SubAgentMiddleware to your agent.\n",
    "\n",
    "Middleware is a composable concept, and you can choose to add as many or as few middleware to an agent depending on your use case. That means that you can also use any of the aforementioned middleware independently!\n",
    "\n",
    "#### TodoListMiddleware\n",
    "Planning is integral to solving complex problems. If you’ve used claude code recently, you’ll notice how it writes out a To-Do list before tackling complex, multi-part tasks. You’ll also notice how it can adapt and update this To-Do list on the fly as more information comes in.\n",
    "\n",
    "TodoListMiddleware provides your agent with a tool specifically for updating this To-Do list. Before, and while it executes a multi-part task, the agent is prompted to use the write_todos tool to keep track of what its doing, and what still needs to be done.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de83180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "\n",
    "# TodoListMiddleware is included by default in create_deep_agent\n",
    "# You can customize it if building a custom agent\n",
    "agent = create_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    # Custom planning instructions can be added via middleware\n",
    "    middleware=[\n",
    "        TodoListMiddleware(\n",
    "            system_prompt=\"Use the write_todos tool to...\"  # Optional: Custom addition to the system prompt\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba7535",
   "metadata": {},
   "source": [
    "### FilesystemMiddleware\n",
    "\n",
    "Context engineering is one of the main challenges in building effective agents. This can be particularly hard when using tools that can return variable length results (ex. web_search, rag), as long ToolResults can quickly fill up your context window. FilesystemMiddleware provides four tools to your agent to interact with both short-term and long-term memory.\n",
    "1. ls: List the files in your filesystem\n",
    "2. read_file: Read an entire file, or a certain number of lines from a file\n",
    "3. write_file: Write a new file to your filesystem\n",
    "4. edit_file: Edit an existing file in your filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from deepagents.middleware.filesystem import FilesystemMiddleware\n",
    "\n",
    "# FilesystemMiddleware is included by default in create_deep_agent\n",
    "# You can customize it if building a custom agent\n",
    "agent = create_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-20250514\",\n",
    "    middleware=[\n",
    "        FilesystemMiddleware(\n",
    "            long_term_memory=False,  # Enables access to long-term memory, defaults to False. You must attach a store to use long-term memory.\n",
    "            system_prompt=\"Write to the filesystem when...\",  # Optional custom addition to the system prompt\n",
    "            custom_tool_descriptions={\n",
    "                \"ls\": \"Use the ls tool when...\",\n",
    "                \"read_file\": \"Use the read_file tool to...\"\n",
    "            }  # Optional: Custom descriptions for filesystem tools\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e462e",
   "metadata": {},
   "source": [
    "### SubAgentMiddleware:\n",
    "\n",
    "Handing off tasks to subagents is a great way to isolate context, keeping the context window of the main (supervisor) agent clean while still going deep on a task. The subagents middleware allows you supply subagents through a task tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from deepagents.middleware.subagents import SubAgentMiddleware\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    middleware=[\n",
    "        SubAgentMiddleware(\n",
    "            default_model=\"claude-sonnet-4-20250514\",\n",
    "            default_tools=[],\n",
    "            subagents=[\n",
    "                {\n",
    "                    \"name\": \"weather\",\n",
    "                    \"description\": \"This subagent can get weather in cities.\",\n",
    "                    \"system_prompt\": \"Use the get_weather tool to get the weather in a city.\",\n",
    "                    \"tools\": [get_weather],\n",
    "                    \"model\": \"gpt-4.1\",\n",
    "                    \"middleware\": [],\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
