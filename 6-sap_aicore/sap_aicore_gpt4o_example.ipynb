{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-4o with SAP AI Core - Example Notebook\n",
        "\n",
        "This notebook demonstrates how to use GPT-4o through SAP AI Core's Gen AI Hub.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. SAP AI Core service key configured\n",
        "2. Gen AI Hub SDK installed: `pip install generative-ai-hub-sdk`\n",
        "3. AI Core credentials configured using `aicore configure -k <path-to-service-key>`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: generative-ai-hub-sdk in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (1.1.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (24.2)\n",
            "Requirement already satisfied: openai>=1.58.1 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (1.93.3)\n",
            "Requirement already satisfied: pydantic==2.10.6 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (2.10.6)\n",
            "Requirement already satisfied: click>=8.1.7 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (0.28.1)\n",
            "Requirement already satisfied: ai-core-sdk>=2.6.1 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (2.6.2)\n",
            "Requirement already satisfied: dacite>=1.8.1 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (1.9.2)\n",
            "Requirement already satisfied: overloading==0.5.0 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from generative-ai-hub-sdk) (0.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from pydantic==2.10.6->generative-ai-hub-sdk) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from pydantic==2.10.6->generative-ai-hub-sdk) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from pydantic==2.10.6->generative-ai-hub-sdk) (4.14.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from requests) (2025.7.9)\n",
            "Requirement already satisfied: ai-api-client-sdk==2.6.1 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from ai-core-sdk>=2.6.1->generative-ai-hub-sdk) (2.6.1)\n",
            "Requirement already satisfied: aenum~=3.1 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.1->generative-ai-hub-sdk) (3.1.16)\n",
            "Requirement already satisfied: pyhumps~=3.0 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from ai-api-client-sdk==2.6.1->ai-core-sdk>=2.6.1->generative-ai-hub-sdk) (3.8.0)\n",
            "Requirement already satisfied: anyio in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->generative-ai-hub-sdk) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from openai>=1.58.1->generative-ai-hub-sdk) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from openai>=1.58.1->generative-ai-hub-sdk) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from openai>=1.58.1->generative-ai-hub-sdk) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/I572648/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages (from openai>=1.58.1->generative-ai-hub-sdk) (4.67.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run once)\n",
        "!pip3 install generative-ai-hub-sdk requests python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from gen_ai_hub.proxy.native.openai import OpenAI\n",
        "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "DistributionNotFound",
          "evalue": "The 'gen-ai-hub' distribution was not found and is required by the application",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mDistributionNotFound\u001b[39m                      Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpkg_resources\u001b[39;00m \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpkg_resources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgen-ai-hub\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.version)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages/pkg_resources/__init__.py:526\u001b[39m, in \u001b[36mget_distribution\u001b[39m\u001b[34m(dist)\u001b[39m\n\u001b[32m    524\u001b[39m     dist = Requirement.parse(dist)\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Requirement):\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     dist = \u001b[43mget_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Distribution):\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExpected str, Requirement, or Distribution\u001b[39m\u001b[33m\"\u001b[39m, dist)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages/pkg_resources/__init__.py:417\u001b[39m, in \u001b[36mget_provider\u001b[39m\u001b[34m(moduleOrReq)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m working_set.find(moduleOrReq) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mrequire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmoduleOrReq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    419\u001b[39m     module = sys.modules[moduleOrReq]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages/pkg_resources/__init__.py:1065\u001b[39m, in \u001b[36mWorkingSet.require\u001b[39m\u001b[34m(self, *requirements)\u001b[39m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequire\u001b[39m(\u001b[38;5;28mself\u001b[39m, *requirements: _NestedStr) -> \u001b[38;5;28mlist\u001b[39m[Distribution]:\n\u001b[32m   1057\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[32m   1058\u001b[39m \n\u001b[32m   1059\u001b[39m \u001b[33;03m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1063\u001b[39m \u001b[33;03m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m     needed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m needed:\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28mself\u001b[39m.add(dist)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages/pkg_resources/__init__.py:892\u001b[39m, in \u001b[36mWorkingSet.resolve\u001b[39m\u001b[34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[39m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m req_extras.markers_pass(req, extras):\n\u001b[32m    890\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m dist = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve_dist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_conflicting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstaller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_activate\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[38;5;66;03m# push the new requirements onto the stack\u001b[39;00m\n\u001b[32m    897\u001b[39m new_requirements = dist.requires(req.extras)[::-\u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/experience-generation-server-YGMb2DSZ-py3.11/lib/python3.11/site-packages/pkg_resources/__init__.py:933\u001b[39m, in \u001b[36mWorkingSet._resolve_dist\u001b[39m\u001b[34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[39m\n\u001b[32m    931\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    932\u001b[39m             requirers = required_by.get(req, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m DistributionNotFound(req, requirers)\n\u001b[32m    934\u001b[39m     to_activate.append(dist)\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m req:\n\u001b[32m    936\u001b[39m     \u001b[38;5;66;03m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n",
            "\u001b[31mDistributionNotFound\u001b[39m: The 'gen-ai-hub' distribution was not found and is required by the application"
          ]
        }
      ],
      "source": [
        "import pkg_resources \n",
        "print(pkg_resources.get_distribution('gen-ai-hub').version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure AI Core Credentials\n",
        "\n",
        "### Option A: Using Service Key File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ AI Core credentials configured\n"
          ]
        }
      ],
      "source": [
        "# Path to your AI Core service key JSON file\n",
        "service_key_path = \"../aicore-service-key.json\"\n",
        "\n",
        "# Load service key\n",
        "with open(service_key_path, 'r') as f:\n",
        "    service_key = json.load(f)\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['AICORE_AUTH_URL'] = service_key['url']\n",
        "os.environ['AICORE_CLIENT_ID'] = service_key['clientid']\n",
        "os.environ['AICORE_CLIENT_SECRET'] = service_key['clientsecret']\n",
        "os.environ['AICORE_RESOURCE_GROUP'] = 'default'\n",
        "\n",
        "# Parse serviceurls - it might be a string or already a dict\n",
        "serviceurls = service_key['serviceurls']\n",
        "if isinstance(serviceurls, str):\n",
        "    serviceurls = json.loads(serviceurls)\n",
        "os.environ['AICORE_BASE_URL'] = serviceurls['AI_API_URL']\n",
        "\n",
        "print(\"✓ AI Core credentials configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Using CLI Configuration\n",
        "\n",
        "If you've already configured using `aicore configure`, you can skip Option A:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using existing AI Core configuration\n"
          ]
        }
      ],
      "source": [
        "# If already configured via CLI, credentials are stored in ~/.aicore/config.json\n",
        "# No additional setup needed - SDK will automatically use stored credentials\n",
        "print(\"✓ Using existing AI Core configuration\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize OpenAI Client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ OpenAI client initialized\n"
          ]
        }
      ],
      "source": [
        "# Initialize the OpenAI client through SAP AI Core proxy\n",
        "client = OpenAI()\n",
        "\n",
        "print(\"✓ OpenAI client initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Basic Chat Completion with GPT-4o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error calling GPT-4o: name 'client' is not defined\n",
            "Error type: NameError\n"
          ]
        }
      ],
      "source": [
        "# Simple chat completion example\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is SAP AI Core?\"}\n",
        "        ],\n",
        "        max_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    \n",
        "    # Check if response has choices\n",
        "    if response.choices and len(response.choices) > 0:\n",
        "        print(\"Response:\")\n",
        "        print(response.choices[0].message.content)\n",
        "        print(f\"\\nTokens used: {response.usage.total_tokens}\")\n",
        "    else:\n",
        "        print(\"Error: No response choices returned from the API\")\n",
        "        print(f\"Full response: {response}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error calling GPT-4o: {e}\")\n",
        "    print(f\"Error type: {type(e).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Streaming Response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streaming response:\n",
            "\n",
            "In the vast domain where data flows,  \n",
            "Clouds weave the threads that knowledge sews,  \n",
            "AI's whispers, soft and clear,  \n",
            "Guide us through, or lend an ear.  \n",
            "\n",
            "Electric thoughts in circuits race,  \n",
            "Learning patterns, keeping pace.  \n",
            "Within the cloud, a cosmic dance,  \n",
            "Of ones and zeros, a chance romance.  \n",
            "\n",
            "Together they sculpt a virtual sky,  \n",
            "Where dreams and reality unify.  \n",
            "Boundless realms of code's embrace,  \n",
            "In synergy, they carve out space.  \n",
            "\n",
            "From human minds, a spark ignites,  \n",
            "With cloud and AI in shared flights,  \n",
            "Towards futures bright with fathomless scope,  \n",
            "In the ether's art, we find our hope.  \n",
            "\n",
            "✓ Streaming complete\n"
          ]
        }
      ],
      "source": [
        "# Streaming example for real-time response\n",
        "print(\"Streaming response:\\n\")\n",
        "\n",
        "try:\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Write a short poem about AI and cloud computing.\"}\n",
        "        ],\n",
        "        stream=True,\n",
        "        max_tokens=200\n",
        "    )\n",
        "    \n",
        "    for chunk in stream:\n",
        "        if chunk.choices and len(chunk.choices) > 0:\n",
        "            if chunk.choices[0].delta.content is not None:\n",
        "                print(chunk.choices[0].delta.content, end=\"\")\n",
        "    \n",
        "    print(\"\\n\\n✓ Streaming complete\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nError during streaming: {e}\")\n",
        "    print(f\"Error type: {type(e).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Multi-turn Conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: SAP BTP stands for SAP Business Technology Platform. It is a comprehensive platform that provides a suite of services and solutions for enterprises to accelerate their digital transformation. SAP BTP integrates various technologies and services, enabling organizations to develop, deploy, and manage applications and services effectively. Here are its key components:\n",
            "\n",
            "1. **Database and Data Management**: SAP BTP offers powerful database solutions including SAP HANA, which provides advanced data processing capabilities. It also includes data integration and data warehousing solutions to handle large volumes of data efficiently.\n",
            "\n",
            "2. **Analytics**: The platform offers tools for business intelligence, planning, and predictive analytics. SAP Analytics Cloud is part of this layer, enabling organizations to gain insights from their data through intuitive dashboards and reporting.\n",
            "\n",
            "3. **Application Development and Integration**: SAP BTP provides tools for developing, deploying, and extending applications. It includes support for both cloud-native development and traditional application development. Integration capabilities allow seamless connections between SAP systems, third-party applications, and on-premise systems.\n",
            "\n",
            "4. **Intelligent Technologies**: This includes technologies such as machine learning, artificial intelligence, Internet of Things (IoT), and blockchain, which help automate processes, create intelligent solutions, and derive insights from data.\n",
            "\n",
            "5. **Services and Tools**: SAP BTP offers various services, such as identity management, security, compliance, and operational control, ensuring governance and seamless management of applications and data.\n",
            "\n",
            "Overall, SAP BTP is designed to support the entire enterprise through enhanced\n",
            "\n",
            "================================================================================\n",
            "\n",
            "User: How does it integrate with AI Core?\n",
            "\n",
            "Assistant: SAP AI Core is part of SAP’s suite of intelligent technologies, designed to facilitate the management and deployment of AI models within the SAP ecosystem, including SAP Business Technology Platform (BTP). Integration between SAP BTP and SAP AI Core offers a streamlined approach to leveraging artificial intelligence within business processes. Here's how this integration typically works:\n",
            "\n",
            "1. **Unified Development Environment**: SAP BTP provides a comprehensive environment where developers can use various tools to create and deploy applications. AI models developed using SAP AI Core can be integrated into applications running on BTP, allowing for seamless use of AI capabilities.\n",
            "\n",
            "2. **Model Deployment and Management**: SAP AI Core is designed for the efficient deployment and management of AI models. These models can be created using popular AI frameworks and languages. Once developed, they can be deployed within the SAP BTP environment, which ensures that models are accessible and operational in integrated applications or services.\n",
            "\n",
            "3. **Scalability and Performance**: Integration with SAP BTP allows AI models managed by SAP AI Core to leverage the robust infrastructure of the platform, including cloud resources. This ensures scalability, enhanced performance, and the ability to handle large data volumes and high-frequency request rates.\n",
            "\n",
            "4. **Seamless Data Flow**: SAP BTP offers powerful data management services, facilitating the seamless flow of data between different components and services, including AI models. This ensures that AI models have access to the necessary data, whether it’s coming from SAP applications, third-party services, or other integrated\n"
          ]
        }
      ],
      "source": [
        "# Maintain conversation history\n",
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful SAP technology expert.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is SAP BTP?\"}\n",
        "]\n",
        "\n",
        "try:\n",
        "    # First exchange\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=conversation_history,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    \n",
        "    if response.choices and len(response.choices) > 0:\n",
        "        assistant_message = response.choices[0].message.content\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "        \n",
        "        print(\"Assistant:\", assistant_message)\n",
        "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "        \n",
        "        # Follow-up question\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": \"How does it integrate with AI Core?\"})\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=conversation_history,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        \n",
        "        if response.choices and len(response.choices) > 0:\n",
        "            print(\"User: How does it integrate with AI Core?\")\n",
        "            print(\"\\nAssistant:\", response.choices[0].message.content)\n",
        "        else:\n",
        "            print(\"Error: No response for follow-up question\")\n",
        "    else:\n",
        "        print(\"Error: No response for initial question\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error in conversation: {e}\")\n",
        "    print(f\"Error type: {type(e).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Advanced Configuration Options\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creative Description:\n",
            "**Introducing ChatMaster 3000: Your Ultimate AI Conversational Companion**\n",
            "\n",
            "Step into the future of communication with ChatMaster 3000, the most advanced AI-powered chatbot designed to transform every interaction into a delightful experience. Crafted with cutting-edge technology and an intuitive design, ChatMaster 3000 is not just a tool—it's your gateway to seamless conversations and intelligent interactions.\n",
            "\n",
            "**Features:**\n",
            "\n",
            "- **Intelligent Conversations:** Equipped with natural language processing capabilities, ChatMaster 3000 understands context and nuances like never before. Whether discussing complex topics or casual chit-chat, it adapts to your style.\n",
            "\n",
            "- **24/7 Availability:** Never wait for a response again! ChatMaster 3000 is always on, ready to assist with any query at any time. Whether you’re planning your day or seeking support, it’s there when you need it.\n",
            "\n",
            "- **Personalized Interactions:** Learning from every conversation, ChatMaster 3000 evolves alongside you. It remembers your preferences and tailors responses to make interactions increasingly relevant.\n",
            "\n",
            "- **Multi-Lingual Mastery:** Break down language barriers effortlessly! With proficiency in over 50 languages, communicate fluently without the constraints of vocabulary or grammar.\n",
            "\n",
            "- **Privacy First:** Your data security is our priority. Powered by robust encryption protocols, all conversations remain confidential and secure.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "From personal assistant functions like scheduling appointments and setting reminders to offering insights on global news trends—ChatMaster 3000 does it all with elegance. Perfect\n",
            "\n",
            "Finish reason: length\n",
            "Model: gpt-4o-2024-08-06\n"
          ]
        }
      ],
      "source": [
        "# Example with various parameters\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative writer.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Write a creative product description for an AI-powered chatbot.\"}\n",
        "        ],\n",
        "        max_tokens=300,\n",
        "        temperature=0.9,        # Higher = more creative (0.0 - 2.0)\n",
        "        top_p=0.95,            # Nucleus sampling\n",
        "        frequency_penalty=0.5,  # Reduce repetition (-2.0 - 2.0)\n",
        "        presence_penalty=0.3,   # Encourage new topics (-2.0 - 2.0)\n",
        "        n=1                     # Number of completions to generate\n",
        "    )\n",
        "    \n",
        "    if response.choices and len(response.choices) > 0:\n",
        "        print(\"Creative Description:\")\n",
        "        print(response.choices[0].message.content)\n",
        "        print(f\"\\nFinish reason: {response.choices[0].finish_reason}\")\n",
        "        print(f\"Model: {response.model}\")\n",
        "    else:\n",
        "        print(\"Error: No response choices returned\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error with advanced configuration: {e}\")\n",
        "    print(f\"Error type: {type(e).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Error Handling and Best Practices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAP AI Core is a scalable, high-performance AI foundation service that enables the management and deployment of AI models and workflows within SAP's ecosystem.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAIError, RateLimitError, APIError\n",
        "import time\n",
        "\n",
        "def safe_chat_completion(messages, max_retries=3, retry_delay=2):\n",
        "    \"\"\"Wrapper with error handling and retry logic\"\"\"\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=messages,\n",
        "                max_tokens=500,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response\n",
        "            \n",
        "        except RateLimitError as e:\n",
        "            print(f\"Rate limit exceeded. Retrying in {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "            retry_delay *= 2  # Exponential backoff\n",
        "            \n",
        "        except APIError as e:\n",
        "            print(f\"API Error: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(retry_delay)\n",
        "            else:\n",
        "                raise\n",
        "                \n",
        "        except OpenAIError as e:\n",
        "            print(f\"OpenAI Error: {e}\")\n",
        "            raise\n",
        "            \n",
        "    raise Exception(\"Max retries exceeded\")\n",
        "\n",
        "# Use the wrapper\n",
        "try:\n",
        "    response = safe_chat_completion([\n",
        "        {\"role\": \"user\", \"content\": \"Explain SAP AI Core in one sentence.\"}\n",
        "    ])\n",
        "    print(response.choices[0].message.content)\n",
        "except Exception as e:\n",
        "    print(f\"Failed to get response: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook covered:\n",
        "- ✅ Setting up SAP AI Core credentials\n",
        "- ✅ Basic chat completions\n",
        "- ✅ Streaming responses\n",
        "- ✅ Multi-turn conversations\n",
        "- ✅ Advanced configuration options\n",
        "- ✅ Error handling and retries\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "- [SAP AI Core Documentation](https://help.sap.com/docs/AI_CORE)\n",
        "- [Gen AI Hub SDK Documentation](https://github.com/SAP/generative-ai-hub-sdk)\n",
        "- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "experience-generation-server-YGMb2DSZ-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
